---
title: "Lab 5: Resampling"
output: 
  html_document: 
    highlight: pygments
    theme: spacelab
---

```{r, include=FALSE}
library(dplyr)
library(magrittr)
library(ggplot2)

```


### Past Performance, Future Results[^1]

Our data set this week looks at the relationship between US stock prices, the earnings of the corporations, and the returns on investment in stocks, with returns counting both changes in stock price and dividends paid to stock holders. A corporation's **earnings** in a given year is its income minus its expenses. The return on an investment over a year is the fractional change in its value, $(v_{t+1} - v_t)/v_t$, and the average rate of return over $k$ years is $[(v_{t+k} - v_t)/v_t]^{1/k}$.  

Specifically, our data contains the following variables:

- `Date`, with fractions of a year indicating months
- `Price` of an index of US stocks (inflation-adjusted)
- `Earnings` per share (also inflation-adjusted);
- `Earnings_10MA_back`, a ten-year moving average of earnings, looking backwards from the current date;
- `Return_cumul`, cumulative return of investing in the stock index,  from the beginning;
- `Return_10_fwd`, the average rate of return over the next 10 years from the current date.

"Returns" will refer to `Return_10_fwd` throughout.

### 1. Inventing a variable
a. Add a new column, `MAPE` to the data frame, which is the ratio of `Price` to `Earnings_10MA_back`. Bring up the summary statistics for the new column using the `summary()` command. Why are there exactly 120 NAs? For ease of computing for the rest of the lab, you may want to remove all rows with any missing data.
b. Build a linear model to predict the returns of `MAPE`. What is the coefficient and it's standard error? Is it significant?
c. What is the MSE of this model under five-fold CV? I recommend you go about this by adding a column to your data frame indicating the randomly assigned *fold* to which every observation belongs. Then use a for-loop to fit and predict across each of the five folds, where you can use the appropriate data by subsetting based on the fold.

```{r}
d <- read.csv("http://andrewpbray.github.io/math-243/assets/data/stock_history.csv")
# a
d %<>% mutate(MAPE = Price/Earnings_10MA_back)
summary(d$MAPE)
d %<>% na.omit()

#b
m1 <- lm(Return_10_fwd ~ MAPE, data=d)
summary(m1)

#c
d$fold <- rep(1:5, length.out = nrow(d))
set.seed(76)
d$fold <- sample(d$fold)
MSE_vec <- c()

MSE <- function(model,testset){
  yhat <- predict(model, newdata=testset)
  MSE <- mean((yhat-testset$Return_10_fwd)^2)
  return(MSE)
  
}

for(i in 1:5){
  train <- d %>% filter(fold != i)
  test <- d %>% filter(fold == i)
  model <- lm(Return_10_fwd ~ MAPE, data=train)
  
  MSE_vec <- append(MSE_vec,(MSE(model,test)))
}


```

a - The first 120 rows (10 years over 12 months) did not have a 10 year moving average earnings because there's not enough trailing earnings data yet.

b - The coefficient and standard error for MAPE is `r summary(m1)$coefficients[2,1:2]`. It is very significant.

c - The MSE from 5-fold CV is `r mean(MSE_vec)`.

### 2. Inverting a variable
a. Build a linear model to predict returns using `1/MAPE` (and nothing else). What is the coefficient and its standard error? Is it significant?
b. What is the CV MSE of this model? How does it compare to the previous one?

```{r}
#a
d %<>% mutate(Inv_MAPE = 1/MAPE)

m2 <- lm(Return_10_fwd ~ Inv_MAPE, data=d)


#b
MSE_vec_2 <- c()

for(i in 1:5){
  train <- d %>% filter(fold != i)
  test <- d %>% filter(fold == i)
  model <- lm(Return_10_fwd ~ Inv_MAPE, data=train)
  
  MSE_vec_2 <- append(MSE_vec_2,(MSE(model,test)))
}

```

a - The coefficient and standard error for MAPE is `r summary(m2)$coefficients[2,1:2]`. It is very significant.

b - The MSE from 5-fold CV is `r mean(MSE_vec_2)` which is virtually identical to the previous result.

### 3. A simple model
A simple-minded model says that the expected returns over the next ten years should be exactly equal to `1/MAPE`.

a. Find the *training* MSE for this model.
b. Explain why the training MSE is equivalent the estimate of test MSE that we would
get through five-fold CV.

```{r}
errors <- (d$Return_10_fwd - d$Inv_MAPE)^2

```

a - The training MSE for this model is `r mean(errors)`.
b - The simple model doesn't change based on training data since it's fixed at 1/MAPE as the only predictor with the same coefficient.

### 4. Is simple sufficient?
The model that we fit in no. 2 is very similar to the simple-minded model. Let's compare the similarity in these models. We could go about this in two ways. We could *simulate* from the simple-minded model many times and fit a model of the same form as no. 2 to each one to see if our observed slope in no. 2 is probable under the simple-minded model. We could also *bootstrap* the data set many times, fitting model 2 each time, then see where the simple-minded model lays in that distribution. Since we already have practiced with simulation, let's do the bootstrap method.

a. Form the bootstrap distribution for the slope of `1/MAPE` (slides from last class may be helpful). Plot this distribution with the paramter of interest (the slope corresponding to the simple-minded model) indicated by a vertical line.
b. What is the approximate 95% bootstrap confidence interval for the slope? How does this interval compare to the one returned by running `confint()` on your model object from question 2? Please explain any difference you've found.

```{r}
#a
betas <- rep(NA, 5000)
for(i in 1:5000) {
  boot_ind <- sample(1:nrow(d), size = nrow(d), replace = TRUE)
  d_boot <- d[boot_ind, ]
  betas[i] <- coef(lm(Return_10_fwd ~ Inv_MAPE, data = d_boot))[2]
}

betas_df <- data.frame(betas)
ggplot(betas_df, aes(betas)) + geom_histogram() +
  geom_vline(xintercept=1, col="red", linetype="dashed") +
  ggtitle("Bootstrapped Betas")

```

b - The 95% bootstrap confidence interval for the betas is `r quantile(betas, c(.025,.975))`. The parametric confidence interval for the betas is `r confint(m2)[2,]` which is slightly more uncertain (wide) than the bootstrap confidence interval. This could just be due to sampling variability since the difference is small. It could also be due to the fact that one or more of the OLS assumptions have been violated (such as consistent variance).

### 5. One big happy plot
For this problem, you need to only include one plot and one paragraph of writing. Also, in this problem, take "line" to mean "straight or curved line" as appropriate, and be sure to plot actual lines and not disconnected points.

a. Make a scatterplot of the returns against `MAPE`.
b. Add two lines showing the predictions from the models you fit in problems 1 and 2.
c. Add a line showing the predictions from the simple-minded model from problem 3.

```{r}

MAPE <- seq(min(d$MAPE),max(d$MAPE),1)
graph <- data.frame(MAPE)
graph %<>% mutate(Return_10_fwd = 1/MAPE)

ggplot(d, aes(x=MAPE, y=Return_10_fwd)) + geom_point(col="pink") +
  ylab("Return") +
  ggtitle("Correlation Between MAPE and Return") +
  geom_smooth(method="lm",se=FALSE,aes(col="MAPE")) +
  geom_smooth(method="lm",se=FALSE,formula= y ~ I(1/x),aes(col="Inverse MAPE")) +
  geom_smooth(data=graph, se=FALSE, aes(col="Simple")) +
  scale_color_manual(name="Model", values= c("MAPE"="red","Inverse MAPE"="blue",   "Simple"="green"))
```


### The big picture
a. **Cross-validation for model selection**: using CV MSE, which model would you select to make predictions of returns? Looking at the plot in question 5, does this seem like a good model? What are it's strengths and weaknesses for prediction?
b. **Bootstrapping for uncertainty estimation**: based on your bootstrapping procedure for the slope of the linear model using `1/MAPE` as a predictor, is the simple-minded model a plausible model given our data?

a - Based on the CV MSE, I would use the second model to predict returns given it has the lowest MSE. It appears to be a decent fit according to the graph. However, the first model appears to do better for higher values of MAPE since that section appears to have a more linear relationship.

b - Yes, the simple minded model uses a beta that is contained in the bootstrapped confidence interval.





[^1]: Based on a homework of Cosma Shalizi at CMU.

